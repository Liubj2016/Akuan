<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Akuan : 面白い人間になりたい">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>learn</title>
  </head>

  <body>
      <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/Liubj2016/Akuan">View on GitHub</a>
          <div class="clearfix">
                <ul id="menu" class="drop">
                    <li><a href="http://liubj2016.github.io/Akuan">Home</a></li>
                    <li><a>liubaojie2016@163.com</163></a></li>
                </ul>
            </div>

          <h1 id="project_title">Akuan</h1>
          <h2 id="project_tagline">面白い人間になりたい</h2>

            
        </header>
    </div>

    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
<!-- 以上是需要的头 -->



<div class="markdown-body">
  <h1>
<a id="user-content-主成分分析pca" class="anchor" href="#%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90pca" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>主成分分析（PCA）</h1>

<blockquote>
<p>主成分分析（PCA）是一种数据降维技巧，它能将大量相关变量转化为一组很少的不相关变
量，这些无关变量称为主成分。</p>
</blockquote>

<p><img src="images/PCA1.png" alt="image"></p>

<p>PCA和EFA最常见的步骤如下：</p>

<ol>
<li>
<strong>数据预处理</strong>。可以输入原始数据矩阵或者相关系数矩阵到<code>principal()</code>和<code>fa()</code>函数中。输入初始数据，相关系数矩阵将会被自动计算，需要确保数据中没有缺失值。</li>
<li>
<strong>选择因子模型</strong>。判断<strong>PCA(数据降维)</strong>还是<strong>EFA(发现潜在结构)</strong>更符合你的研究目的。</li>
</ol>

<p><strong>PCA</strong>的目标是用一组较少的不相关变量代替大量相关变量，同时尽可能保留初始变量的信息。如第一主成分为：</p>

<p><span title="MathGene HTML"><i>P</i><i>C</i><sub><sub>1</sub></sub> = <i>a</i><sub><sub>1</sub></sub><i>X</i><sub><sub>1</sub></sub>+<i>a</i><sub><sub>2</sub></sub><i>X</i><sub><sub>2</sub></sub>+…+<i>a</i><sub><sub><i>k</i></sub></sub><i>X</i><sub><sub><i>k</i></sub></sub></span></p>

<p>它是k个观测变量的加权组合，对初始变量集的方差解释性<strong>最大</strong>。第二主成分也是初始变量的线性组合，对方差的解释性排<strong>第二</strong>，同时与第一主成分<strong>正交</strong>（不相关）。</p>

<p>PCA的目标是找到一个满足如下性质的数据变换：</p>

<ol>
<li>每对(不同的)新属性的协方差为0；</li>
<li>属性按照每个属性捕获的方差多少来排序；</li>
<li>每一个属性捕获尽可能多的数据方差。</li>
<li>在满足正交的前提下，每个后继属性捕获尽可能多的剩余方差。</li>
</ol>

<p>假设存在数据集D，令其协方差矩阵为S，将S的特征值排序，U是S的特征向量矩阵，最后假设已经对数据矩阵D进行过预处理，使得每个属性(列)的均值为0，则有：</p>

<ul>
<li>数据矩阵D'=DU是变换后的数据集，满足以上条件。</li>
<li>每个新属性都是原属性的线性组合。</li>
<li>第i个新属性的方差就是S的第i个特征值。</li>
<li>原属性的方差和等于新属性的方差和。</li>
</ul>

<h2>
<a id="user-content-判断主成分的个数" class="anchor" href="#%E5%88%A4%E6%96%AD%E4%B8%BB%E6%88%90%E5%88%86%E7%9A%84%E4%B8%AA%E6%95%B0" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>判断主成分的个数</h2>

<p>一些准则：</p>

<ul>
<li>根据先验经验和理论知识判断主成分数；</li>
<li>根据要解释变量方差的积累值的阈值来判断需要的主成分数；</li>
<li>通过检查变量间k × k的相关系数矩阵来判断保留的主成分数。</li>
</ul>

<p><img src="images/PCA2.png" alt="image"></p>

<div class="highlight highlight-source-r"><pre>library(<span class="pl-smi">psych</span>)
fa.parallel(<span class="pl-smi">USJudgeRatings</span>[,<span class="pl-k">-</span><span class="pl-c1">1</span>],<span class="pl-v">fa</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>pc<span class="pl-pds">"</span></span>,<span class="pl-v">n.iter</span> <span class="pl-k">=</span> <span class="pl-c1">100</span>,<span class="pl-v">show.legend</span> <span class="pl-k">=</span> <span class="pl-c1">FALSE</span>,<span class="pl-v">main</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>Scree plot with parallel analysis<span class="pl-pds">"</span></span>)</pre></div>

<p>表明选择一个主成分即可保留数据集的大部分信息。</p>

<h2>
<a id="user-content-提取主成分" class="anchor" href="#%E6%8F%90%E5%8F%96%E4%B8%BB%E6%88%90%E5%88%86" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>提取主成分</h2>

<p>美国法官评分的主成分分析的例子：</p>

<div class="highlight highlight-source-r"><pre>library(<span class="pl-smi">psych</span>)
<span class="pl-smi">pc</span><span class="pl-k">&lt;-</span>principal(<span class="pl-smi">USJudgeRatings</span>[,<span class="pl-k">-</span><span class="pl-c1">1</span>],<span class="pl-v">nfactors</span> <span class="pl-k">=</span> <span class="pl-c1">1</span>)
<span class="pl-smi">pc</span></pre></div>

<pre><code>$output
Principal Components Analysis
Call: principal(r = USJudgeRatings[, -1], nfactors = 1)
Standardized loadings (pattern matrix) based upon correlation matrix
      PC1   h2     u2 com
INTG 0.92 0.84 0.1565   1
DMNR 0.91 0.83 0.1663   1
DILG 0.97 0.94 0.0613   1
CFMG 0.96 0.93 0.0720   1
DECI 0.96 0.92 0.0763   1
PREP 0.98 0.97 0.0299   1
FAMI 0.98 0.95 0.0469   1
ORAL 1.00 0.99 0.0091   1
WRIT 0.99 0.98 0.0196   1
PHYS 0.89 0.80 0.2013   1
RTEN 0.99 0.97 0.0275   1

                 PC1
SS loadings    10.13
Proportion Var  0.92
</code></pre>

<p>此处可以看到，第一主成分（PC1）与每个变量都高度相关，也就是说，它是一个可以用来进行一般性评价的难度。<br>
h2栏指成分<strong>公因子方差</strong>——主成分对每个变量方差的解释度。u2是成分<strong>唯一性</strong>——方差无法被主成分解释的比例（1-h2）。例如，体能（PHYS）80%的方差都能由第一主成分来解释，20%不能。<br>
Proportion Var行表示的是每个主成分对整个数据集的解释程度。此处可以看到，第一主成分解释了11个变量92%的方差。</p>

<h2>
<a id="user-content-主成分旋转" class="anchor" href="#%E4%B8%BB%E6%88%90%E5%88%86%E6%97%8B%E8%BD%AC" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>主成分旋转</h2>

<p>旋转可以用来<strong>去噪</strong>。旋转方法有两种：使选择的成分保持不变（<strong>正交旋转</strong>），和让他们变得相关（<strong>斜交旋转</strong>）。最流行的正交旋转是<strong>方差极大</strong>旋转。</p>

<p>例子：</p>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">rc</span><span class="pl-k">&lt;-</span>principal(<span class="pl-smi">Harman23.cor</span><span class="pl-k">$</span><span class="pl-smi">cov</span>,<span class="pl-v">nfactors</span> <span class="pl-k">=</span> <span class="pl-c1">2</span>,<span class="pl-v">rotate</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>varimax<span class="pl-pds">"</span></span>)
<span class="pl-smi">rc</span></pre></div>

<pre><code>$output
Principal Components Analysis
Call: principal(r = Harman23.cor$cov, nfactors = 2, rotate = "varimax")
Standardized loadings (pattern matrix) based upon correlation matrix
                PC1  PC2   h2    u2 com
height         0.90 0.25 0.88 0.123 1.2
arm.span       0.93 0.19 0.90 0.097 1.1
forearm        0.92 0.16 0.87 0.128 1.1
lower.leg      0.90 0.22 0.86 0.139 1.1
weight         0.26 0.88 0.85 0.150 1.2
bitro.diameter 0.19 0.84 0.74 0.261 1.1
chest.girth    0.11 0.84 0.72 0.283 1.0
chest.width    0.26 0.75 0.62 0.375 1.2

                       PC1  PC2
SS loadings           3.52 2.92
Proportion Var        0.44 0.37
Cumulative Var        0.44 0.81
</code></pre>

<p>观察输出，发现第一主成分主要由前四个变量来解释，第二个主成分则由后四个变量来解释。两个主成分仍然不相关，对变量的解释性不变。</p>

</div>




  <!-- 以下是需要的尾 -->


<hr>
    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Akuan maintained by <a href="https://github.com/Liubj2016">Liubj2016</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>   

  </body>
</html>